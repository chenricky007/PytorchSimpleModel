{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987a6af6-307e-4c51-806f-eed931cb8dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\pytorch_py36\\lib\\site-packages\\numpy\\__init__.py:138: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\n",
      "  from . import _distributor_init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 設定使用gpu訓練\n",
    "CUDA = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 輸出cuda代表有使用gpu\n",
    "print(device)\n",
    "\n",
    "# 設定batch大小\n",
    "batch_size = 64\n",
    "\n",
    "# 設定data前處理以及augmentation\n",
    "# 加入transforms.ToTensor()將資料轉換為tensor\n",
    "train_transform = transforms.Compose([\n",
    "                  transforms.RandomResizedCrop(size = (256,256),scale=(0.7, 1.0), ratio=(1.0, 1.0)),\n",
    "                  transforms.RandomHorizontalFlip(p = 0.5),\n",
    "                  transforms.Resize((256, 256)),\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# validation data也需要做前處理\n",
    "val_transform = transforms.Compose([\n",
    "                  transforms.Resize((256, 256)),\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 使用torchvision.datasets.ImageFolder讀取training data\n",
    "image_folder = ImageFolder('D:/project/dataset/AnimalFaces/afhq/train', transform = train_transform, target_transform = None)\n",
    "# 建立DataLoader，shuffle = True表示會將data順序打亂\n",
    "train_loader = DataLoader(dataset = image_folder, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "\n",
    "# 使用torchvision.datasets.ImageFolder讀取validation data\n",
    "val_image_folder = ImageFolder('D:/project/dataset/AnimalFaces/afhq/val', transform = val_transform, target_transform = None)\n",
    "# 建立DataLoader，shuffle = True表示不會將data順序打亂\n",
    "val_loader = DataLoader(dataset = val_image_folder, batch_size = batch_size, shuffle = False, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d905b0a-e9c6-422a-9840-23709fb46608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立普通Block\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, down_sample = False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.down_sample = down_sample\n",
    "        if self.down_sample:\n",
    "            self.conv1 = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, padding=1, stride=2)\n",
    "            self.conv_shortcut = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=1, stride=2)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_ch, out_channels=out_ch, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_residual = x\n",
    "        if self.down_sample:\n",
    "            x_residual = self.conv_shortcut(x_residual)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = x_residual + x\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "# 建立BottleNeck\n",
    "class BottleNeckBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, down_sample = False):\n",
    "        super(BottleNeckBlock, self).__init__()\n",
    "        self.down_sample = down_sample\n",
    "        if self.down_sample:\n",
    "            self.conv1 = nn.Conv2d(in_channels=in_ch, out_channels=out_ch//4, kernel_size=1, stride=2)\n",
    "            self.conv_shortcut = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=1, stride=2)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels=in_ch, out_channels=out_ch//4, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch//4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_ch//4, out_channels=out_ch//4, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch//4)\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_ch//4, out_channels=out_ch, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_residual = x\n",
    "        if self.down_sample:\n",
    "            x_residual = self.conv_shortcut(x_residual)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = x_residual + x\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "class Blocks(nn.Module):\n",
    "    def __init__(self, Block, in_ch, out_ch, number):\n",
    "        super(Blocks, self).__init__()\n",
    "        self.block_list = nn.ModuleList()\n",
    "        self.block_list.append(Block(in_ch, out_ch, down_sample = True))\n",
    "        for i in range(1, number):\n",
    "            self.block_list.append(Block(out_ch, out_ch, down_sample = False))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.block_list)):\n",
    "            x = self.block_list[i](x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba7ec26-be37-49f8-b7e3-1b0d2fdc1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, BlockType, out_feature = 3, block_num_list = [2, 2, 2, 2], in_channel_list = [64, 64, 128, 256], out_channel_list = [64, 128, 256, 512]):\n",
    "        super(Model, self).__init__()\n",
    "        # 在此加入用到的各項操作\n",
    "        # convolution需指定輸入channel數量以及輸出channel數量\n",
    "        # stride為步長, 在此用來進行down sample操作\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, padding=3, stride=2)\n",
    "        # batch norm需要指定輸入channel數量\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        assert len(block_num_list) == len(in_channel_list), '數量必須相等'\n",
    "        self.blocks_list = nn.ModuleList()\n",
    "        for i in range(len(block_num_list)):\n",
    "            self.blocks_list.append(Blocks(BlockType, in_channel_list[i], out_channel_list[i], block_num_list[i]))\n",
    "\n",
    "        # dropout操作, 注意這裡指定的是drop掉的比例\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(in_features=out_channel_list[-1], out_features=out_feature)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # relu activation function處理\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        # max pooling指定大小, padding和stride\n",
    "        x = F.max_pool2d(x, kernel_size=3, padding=1, stride=2)\n",
    "        # block結構\n",
    "        for i in range(len(self.blocks_list)):\n",
    "            x = self.blocks_list[i](x)\n",
    "        # global max pooling\n",
    "        x = F.max_pool2d(x, kernel_size=x.size()[2:])\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = Model(BasicBlock, out_feature = 3, block_num_list = [3, 4, 6, 3], in_channel_list = [64, 64, 128, 256], out_channel_list = [64, 128, 256, 512])\n",
    "# 若報錯 Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
    "# 需要將model轉換為使用GPU\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5855a082-832e-4735-91b2-8b58ee454ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定loss function以及optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a37b1-574f-4d6c-9467-dbabc8ad1316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0 loss 1.33937311927304 acc 0.506004366812227\n",
      "validation: loss 0.7298508249223232 acc 0.6399739583333334\n",
      "train epoch: 1 loss 0.5650005721889729 acc 0.7941457423580786\n",
      "validation: loss 0.3483299103875955 acc 0.8470052083333334\n"
     ]
    }
   ],
   "source": [
    "# 開始訓練\n",
    "for epoch in range(10):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_step_count = 0.0\n",
    "    # 將model切換為training模式, 影響dropout和BN\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if CUDA:\n",
    "            # 資料轉換為使用GPU\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # 獲取判斷結果\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += torch.sum(predicted == target, dtype = torch.float32).item()/batch_size\n",
    "        train_step_count += 1.0\n",
    "        \n",
    "    print('train epoch:', epoch, 'loss', train_loss/train_step_count, 'acc', train_acc/train_step_count)\n",
    "    \n",
    "    # 每個epoch進行validation\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_step_count = 0.0\n",
    "    # 將model切換模式, 影響dropout和BN\n",
    "    model.eval()\n",
    "    # validation時不計算gradients\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (val_data, val_target) in enumerate(val_loader):\n",
    "            if CUDA:\n",
    "                val_data, val_target = val_data.cuda(), val_target.cuda()\n",
    "            val_output = model(val_data)\n",
    "            val_predicted = torch.max(val_output.data, 1)[1]\n",
    "            val_loss += criterion(val_output, val_target).item()\n",
    "            val_acc += torch.sum(val_predicted == val_target, dtype = torch.float32).item()/batch_size\n",
    "            val_step_count += 1.0\n",
    "        \n",
    "    print('validation:', 'loss', val_loss/val_step_count, 'acc', val_acc/val_step_count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ee4806-e155-4557-8de8-db3e5ff09640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存權重\n",
    "torch.save(model.state_dict(), 'ResNet_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0186527-ac36-4cec-89c6-aea9b4b2fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: acc 0.9427083333333334\n"
     ]
    }
   ],
   "source": [
    "# 讀取權重\n",
    "model.load_state_dict(torch.load('ResNet_weights.pth'))\n",
    "\n",
    "# 可以進行測試集的效果評估, 再此以validation結果代替\n",
    "val_acc = 0.0\n",
    "val_step_count = 0.0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for val_batch_idx, (val_data, val_target) in enumerate(val_loader):\n",
    "        if CUDA:\n",
    "            val_data, val_target = val_data.cuda(), val_target.cuda()\n",
    "        val_output = model(val_data)\n",
    "        val_predicted = torch.max(val_output.data, 1)[1]\n",
    "        val_acc += torch.sum(val_predicted == val_target, dtype = torch.float32).item()/batch_size\n",
    "        val_step_count += 1.0\n",
    "\n",
    "print('validation:', 'acc', val_acc/val_step_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d940e-01f8-4864-ab2d-d108a8a1747d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py36",
   "language": "python",
   "name": "pytorch_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
